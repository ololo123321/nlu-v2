defaults:
  - _self_
  - hydra: hydra_default

model_cls:
  _target_: hydra.utils.get_class
  path: ???

model:
  pretrained_dir: ???
  birnn:
    use: false
    params:
      num_layers: 1
      cell_dim: 256
      dropout: 0.5
      recurrent_dropout: 0.0
  bert:
    test_mode: false
    dropout: 0.2
    scope: bert
    pad_token_id: ???
    cls_token_id: ???
    sep_token_id: ???
    params: ???
    params_updates:
      attention_probs_dropout_prob: 0.5  # default 0.1
      hidden_dropout_prob: 0.1  # default 0.1

tokenizer:
  _target_: bert.tokenization.FullTokenizer
  vocab_file: ${model.pretrained_dir}/vocab.txt
  do_lower_case: false

optimizer:
  init_lr: 2e-5
  warmup_proportion: 0.1

dataset:
  _target_: ???
  data: null
  tokenizer: ???
  tokens_expression: null
  ignore_bad_examples: true
  ignore_without_annotation: true
  max_chunk_length: 512
  window: 1
  stride: 1
  language: ru
  fix_sent_pointers: true
  read_fn:
    _target_: hydra.utils.get_static_method
    path: src.data.io.read_file_v3

training:
  num_epochs: 10
  batch_size: 16
  max_epochs_wo_improvement: 10
  num_train_samples: ???  # need to get learning rate schedule

validation:
  window: ${dataset.window}

inference:
  max_tokens_per_batch: 10000
  window: ${dataset.window}
  max_chunk_length: ${dataset.max_chunk_length}

evaluator:
  _target_: ???
  allow_examples_mismatch: false

# for training
train_data_path: ???
valid_data_path: ???
num_examples_train: -1
num_examples_valid: -1
scope_to_save: null
output_dir: ???

# for inference
test_data_path: ???
predictions_path: ???  # and for evaluation
model_dir: ???
scope_to_load: ${scope_to_save}
num_examples_test: -1

# for evaluation
gold_data_path: ???
metrics_path: null
filter_gold_examples: false