{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0506 08:40:22.112535 140183032723264 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0506 08:40:22.122165 140183032723264 deprecation_wrapper.py:119] From /tf/datadrive/datascientist/relation-extraction/src/model/base.py:62: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "tf = import_tensorflow()\n",
    "from bert.tokenization import FullTokenizer\n",
    "\n",
    "sys.path.insert(0, \"/tf/datadrive/datascientist/relation-extraction/\")\n",
    "from src.model.dependency_parsing import BertForDependencyParsing\n",
    "from src.data.io import from_conllu\n",
    "from src.data.preprocessing import apply_bpe, fit_encodings, apply_encodings\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "assert tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== DATASET INFO =====\n",
      "num documents: 522\n",
      "num sentences: 47962\n",
      "num tokens: 850548\n",
      "num sentences ignored: 852\n",
      "===== DATASET INFO =====\n",
      "num documents: 47\n",
      "num sentences: 6425\n",
      "num tokens: 114371\n",
      "num sentences ignored: 159\n",
      "===== DATASET INFO =====\n",
      "num documents: 53\n",
      "num sentences: 6347\n",
      "num tokens: 113789\n",
      "num sentences ignored: 144\n"
     ]
    }
   ],
   "source": [
    "path_mask = \"/tf/datadrive/data/syntagrus/ru_syntagrus-ud-{}.conllu\"\n",
    "for part in [\"train\", \"dev\", \"test\"]:\n",
    "# for part in [\"dev\", \"test\"]:\n",
    "    path = path_mask.format(part)\n",
    "    if part == \"train\":\n",
    "        examples_train = from_conllu(path=path, warn=False)\n",
    "    elif part == \"dev\":\n",
    "        examples_valid = from_conllu(path=path, warn=False)\n",
    "    elif part == \"test\":\n",
    "        examples_test = from_conllu(path=path, warn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces(s):\n",
    "    return s.replace(' ', '').replace('\\xa0', '')\n",
    "\n",
    "def check():\n",
    "    limit = 5\n",
    "    for x in examples_train + examples_valid + examples_test:\n",
    "        for chunk in x.chunks:\n",
    "            actual = ''.join(remove_spaces(t.text) for t in chunk.tokens)\n",
    "            expected = remove_spaces(chunk.text)\n",
    "            if actual != expected:\n",
    "                print(chunk.id)\n",
    "                print(actual)\n",
    "                print(expected)\n",
    "                print(\"text:\", chunk.text)\n",
    "                print(\"first tokens:\", [t.text for t in chunk.tokens[:500]])\n",
    "                print()\n",
    "                limit -= 1\n",
    "                if limit == 0:\n",
    "                    return\n",
    "check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0506 08:40:43.379161 140183032723264 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bert_dir = \"/tf/datadrive/nn_lfs/rubert_cased_L-12_H-768_A-12_v2/\"\n",
    "tokenizer = FullTokenizer(vocab_file=os.path.join(bert_dir, \"vocab.txt\"), do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in examples_train + examples_valid + examples_test:\n",
    "    for chunk in x.chunks:\n",
    "        apply_bpe(\n",
    "            chunk, \n",
    "            tokenizer=tokenizer, \n",
    "            ner_prefix_joiner=None,\n",
    "            ner_encoding=\"bio\"  # TODO: костыль!!1!\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Алгоритм \t ['Алгоритм']\n",
      ", \t [',']\n",
      "от \t ['от']\n",
      "имени \t ['имени']\n",
      "учёного \t ['учёного']\n",
      "аль \t ['аль']\n",
      "- \t ['-']\n",
      "Хорезми \t ['Хорезм', '##и']\n",
      ", \t [',']\n",
      "- \t ['-']\n",
      "точный \t ['точный']\n",
      "набор \t ['набор']\n",
      "инструкций \t ['инструкций']\n",
      ", \t [',']\n",
      "описывающих \t ['описывающих']\n",
      "порядок \t ['порядок']\n",
      "действий \t ['действий']\n",
      "исполнителя \t ['исполнителя']\n",
      "для \t ['для']\n",
      "достижения \t ['достижения']\n",
      "результата \t ['результата']\n",
      "решения \t ['решения']\n",
      "задачи \t ['задачи']\n",
      "за \t ['за']\n",
      "конечное \t ['конечное']\n",
      "время \t ['время']\n",
      ". \t ['.']\n"
     ]
    }
   ],
   "source": [
    "for t in examples_valid[0].chunks[0].tokens:\n",
    "    print(t.text, \"\\t\", t.pieces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60734 60734\n"
     ]
    }
   ],
   "source": [
    "before = 0\n",
    "after = 0\n",
    "for x in examples_train + examples_valid + examples_test:\n",
    "    before += len(x.chunks)\n",
    "    x.chunks = [chunk for chunk in x.chunks if sum(len(t.pieces) for t in chunk.tokens) <= 256]\n",
    "    after += len(x.chunks)\n",
    "\n",
    "print(before, after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "### encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_labels(examples):\n",
    "    labels = set()\n",
    "    for x in examples:\n",
    "        for chunk in x.chunks:\n",
    "            for t in chunk.tokens:\n",
    "                labels.add(t.rel)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_unique_labels(examples_train + examples_valid + examples_test)\n",
    "rel2id = {label: i for i, label in enumerate(sorted(labels))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "{'acl': 0, 'acl:relcl': 1, 'advcl': 2, 'advmod': 3, 'amod': 4, 'appos': 5, 'aux': 6, 'aux:pass': 7, 'case': 8, 'cc': 9, 'ccomp': 10, 'compound': 11, 'conj': 12, 'cop': 13, 'csubj': 14, 'csubj:pass': 15, 'dep': 16, 'det': 17, 'discourse': 18, 'expl': 19, 'fixed': 20, 'flat': 21, 'flat:foreign': 22, 'flat:name': 23, 'iobj': 24, 'mark': 25, 'nmod': 26, 'nsubj': 27, 'nsubj:pass': 28, 'nummod': 29, 'nummod:entity': 30, 'nummod:gov': 31, 'obj': 32, 'obl': 33, 'orphan': 34, 'parataxis': 35, 'punct': 36, 'root': 37, 'vocative': 38, 'xcomp': 39}\n"
     ]
    }
   ],
   "source": [
    "print(len(rel2id))\n",
    "print(rel2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model\": {\n",
    "        \"bert\": {\n",
    "            \"test_mode\": False,\n",
    "            \"dir\": bert_dir,\n",
    "            \"dim\": 768,\n",
    "            \"attention_probs_dropout_prob\": 0.5,  # default 0.1\n",
    "            \"hidden_dropout_prob\": 0.1,\n",
    "            \"dropout\": 0.2,\n",
    "            \"scope\": \"bert\",\n",
    "            \"pad_token_id\": tokenizer.vocab[\"[PAD]\"],\n",
    "            \"cls_token_id\": tokenizer.vocab[\"[CLS]\"],\n",
    "            \"sep_token_id\": tokenizer.vocab[\"[SEP]\"],\n",
    "            \"root_token_id\": tokenizer.vocab[\"[unused1]\"]\n",
    "        },\n",
    "        \"parser\": {\n",
    "            \"use_birnn\": False,\n",
    "            \"rnn\": {\n",
    "                \"num_layers\": 1,\n",
    "                \"cell_dim\": 8,\n",
    "                \"dropout\": 0.5,\n",
    "                \"recurrent_dropout\": 0.0\n",
    "            },\n",
    "            \"biaffine_arc\": {\n",
    "                \"num_mlp_layers\": 1,\n",
    "                \"activation\": \"relu\",\n",
    "                \"head_dim\": 1024,\n",
    "                \"dep_dim\": 1024,\n",
    "                \"dropout\": 0.33,\n",
    "                \"num_labels\": 1,\n",
    "            },\n",
    "            \"biaffine_type\": {\n",
    "                \"num_mlp_layers\": 1,\n",
    "                \"activation\": \"relu\",\n",
    "                \"head_dim\": 256,\n",
    "                \"dep_dim\": 256,\n",
    "                \"dropout\": 0.33,\n",
    "                \"num_labels\": len(rel2id),\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"num_epochs\": 10,\n",
    "        \"batch_size\": 8,\n",
    "        \"max_epochs_wo_improvement\": 20,\n",
    "        \"num_train_samples\": sum(len(x.chunks) for x in examples_train),\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"init_lr\": 2e-5,\n",
    "        \"warmup_proportion\": 0.1,\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"max_tokens_per_batch\": 10000,\n",
    "        \"window\": 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0506 08:42:21.374456 140183032723264 deprecation_wrapper.py:119] From /tf/datadrive/datascientist/relation-extraction/src/model/base.py:448: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0506 08:42:21.381497 140183032723264 deprecation_wrapper.py:119] From /tf/datadrive/datascientist/relation-extraction/src/model/base.py:124: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0506 08:42:21.389999 140183032723264 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "W0506 08:42:21.437133 140183032723264 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "W0506 08:42:21.790929 140183032723264 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0506 08:42:21.808033 140183032723264 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/bert/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0506 08:42:21.850361 140183032723264 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0506 08:42:25.391846 140183032723264 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0506 08:42:26.292347 140183032723264 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "W0506 08:42:26.297562 140183032723264 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n",
      "W0506 08:42:26.302151 140183032723264 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "W0506 08:42:26.823494 140183032723264 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0506 08:42:43.670752 140183032723264 deprecation_wrapper.py:119] From /tf/datadrive/datascientist/relation-extraction/src/model/base.py:471: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W0506 08:42:43.838678 140183032723264 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess_config = tf.ConfigProto()\n",
    "sess_config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=sess_config)\n",
    "model = BertForDependencyParsing(sess=sess, config=config, rel_enc=rel2id)\n",
    "model.build()\n",
    "model.reset_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/tmp/bert_for_dependency_parsing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbose_fn(d):\n",
    "    print({k: round(v, 4) for k, v in d.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5996 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model dir /tmp/bert_for_dependency_parsing created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5996/5996 [12:25<00:00,  8.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 finished. mean train loss: 2.2538764476776123. evaluation starts.\n",
      "{'loss': 0.5333, 'loss_arc': 0.3679, 'loss_type': 0.1654, 'score': 0.8962, 'uas': 0.9253, 'las': 0.8962}\n",
      "current score: 0.8961624887427757\n",
      "!!! new best score: 0.8961624887427757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/5996 [00:00<12:43,  7.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new head to /tmp/bert_for_dependency_parsing/model.ckpt\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5996/5996 [12:18<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 finished. mean train loss: 1.340116262435913. evaluation starts.\n",
      "{'loss': 0.3953, 'loss_arc': 0.2744, 'loss_type': 0.1208, 'score': 0.9208, 'uas': 0.9419, 'las': 0.9208}\n",
      "current score: 0.9208190887550166\n",
      "!!! new best score: 0.9208190887550166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/5996 [00:00<11:50,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new head to /tmp/bert_for_dependency_parsing/model.ckpt\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5996/5996 [12:14<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 finished. mean train loss: 0.9953550696372986. evaluation starts.\n",
      "{'loss': 0.3596, 'loss_arc': 0.2532, 'loss_type': 0.1063, 'score': 0.9263, 'uas': 0.9455, 'las': 0.9263}\n",
      "current score: 0.9263012476939084\n",
      "!!! new best score: 0.9263012476939084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/5996 [00:00<10:23,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new head to /tmp/bert_for_dependency_parsing/model.ckpt\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5996/5996 [12:15<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 finished. mean train loss: 0.8089344501495361. evaluation starts.\n",
      "{'loss': 0.3359, 'loss_arc': 0.2376, 'loss_type': 0.0984, 'score': 0.9321, 'uas': 0.9498, 'las': 0.9321}\n",
      "current score: 0.9321418891152478\n",
      "!!! new best score: 0.9321418891152478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/5996 [00:00<10:41,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new head to /tmp/bert_for_dependency_parsing/model.ckpt\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5996/5996 [12:17<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 finished. mean train loss: 0.688689649105072. evaluation starts.\n",
      "{'loss': 0.3463, 'loss_arc': 0.2482, 'loss_type': 0.0981, 'score': 0.9338, 'uas': 0.951, 'las': 0.9338}\n",
      "current score: 0.933838123300487\n",
      "!!! new best score: 0.933838123300487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/5996 [00:00<12:22,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new head to /tmp/bert_for_dependency_parsing/model.ckpt\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5996/5996 [12:16<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 finished. mean train loss: 0.6044422388076782. evaluation starts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/5996 [00:00<12:22,  8.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3406, 'loss_arc': 0.2444, 'loss_type': 0.0962, 'score': 0.9337, 'uas': 0.9501, 'las': 0.9337}\n",
      "current score: 0.9336545103216725\n",
      "best score: 0.933838123300487\n",
      "steps wo improvement: 1\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5996/5996 [12:15<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 finished. mean train loss: 0.541215181350708. evaluation starts.\n",
      "{'loss': 0.3491, 'loss_arc': 0.256, 'loss_type': 0.0931, 'score': 0.934, 'uas': 0.9505, 'las': 0.934}\n",
      "current score: 0.9339692754282117\n",
      "!!! new best score: 0.9339692754282117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/5996 [00:00<12:06,  8.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new head to /tmp/bert_for_dependency_parsing/model.ckpt\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5996/5996 [12:14<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 finished. mean train loss: 0.49125516414642334. evaluation starts.\n",
      "{'loss': 0.346, 'loss_arc': 0.251, 'loss_type': 0.0949, 'score': 0.9352, 'uas': 0.9512, 'las': 0.9352}\n",
      "current score: 0.9352283358543687\n",
      "!!! new best score: 0.9352283358543687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/5996 [00:00<11:28,  8.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new head to /tmp/bert_for_dependency_parsing/model.ckpt\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5996/5996 [12:14<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 finished. mean train loss: 0.45110705494880676. evaluation starts.\n",
      "{'loss': 0.3588, 'loss_arc': 0.2632, 'loss_type': 0.0956, 'score': 0.9363, 'uas': 0.9522, 'las': 0.9363}\n",
      "current score: 0.9362862963513479\n",
      "!!! new best score: 0.9362862963513479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/5996 [00:00<12:34,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved new head to /tmp/bert_for_dependency_parsing/model.ckpt\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5996/5996 [12:14<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 finished. mean train loss: 0.4183713495731354. evaluation starts.\n",
      "{'loss': 0.356, 'loss_arc': 0.2605, 'loss_type': 0.0955, 'score': 0.9365, 'uas': 0.9524, 'las': 0.9365}\n",
      "current score: 0.936478652805344\n",
      "!!! new best score: 0.936478652805344\n",
      "saved new head to /tmp/bert_for_dependency_parsing/model.ckpt\n",
      "==================================================\n",
      "restoring model from /tmp/bert_for_dependency_parsing/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    examples_train=examples_train,\n",
    "    examples_valid=examples_valid,\n",
    "    model_dir=model_dir,\n",
    "    verbose=True,\n",
    "    verbose_fn=verbose_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3073, 'loss_arc': 0.2316, 'loss_type': 0.0757, 'score': 0.9451, 'uas': 0.9576, 'las': 0.9451, 'support': 113789}\n"
     ]
    }
   ],
   "source": [
    "d_test = model.evaluate(examples=examples_test)\n",
    "verbose_fn(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deeppavlov: 95.2 (uas), 93.7 (las)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
